{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Cleaning and Feature Engineering**\n",
    "### Stock Analyst Recommendations Dataset\n",
    "\n",
    "This notebook implements the data cleaning recommendations from the exploratory analysis and creates new engineered features for advanced analytics.\n",
    "\n",
    "**Objectives:**\n",
    "1. Clean the dataset by removing problematic columns and records\n",
    "2. Create new numerical features from qualitative data\n",
    "3. Engineer features for rating changes and target price analysis\n",
    "4. Prepare a high-quality dataset for machine learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Import Libraries**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Load and Inspect Original Data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ORIGINAL DATASET OVERVIEW ===\n",
      "Shape: (2797, 9)\n",
      "Columns: ['ticker', 'company', 'target_from', 'target_to', 'action', 'brokerage', 'rating_from', 'rating_to', 'time']\n",
      "\n",
      "Data types:\n",
      "ticker          object\n",
      "company         object\n",
      "target_from    float64\n",
      "target_to      float64\n",
      "action          object\n",
      "brokerage       object\n",
      "rating_from     object\n",
      "rating_to       object\n",
      "time            object\n",
      "dtype: object\n",
      "\n",
      "=== MISSING VALUES ANALYSIS ===\n",
      "             Missing Count  Missing Percentage\n",
      "ticker                   0                0.00\n",
      "company                  0                0.00\n",
      "target_from              0                0.00\n",
      "target_to                0                0.00\n",
      "action                   0                0.00\n",
      "brokerage             1720               61.49\n",
      "rating_from             58                2.07\n",
      "rating_to               58                2.07\n",
      "time                     0                0.00\n",
      "\n",
      "=== SAMPLE DATA ===\n",
      "  ticker                 company  target_from  target_to             action  \\\n",
      "0   CECO      CECO Environmental        44.00      52.00   target raised by   \n",
      "1   BLND              Blend Labs         5.25       5.25      reiterated by   \n",
      "2   FLOC                  Flowco        28.00      26.00  target lowered by   \n",
      "3   VYGR    Voyager Therapeutics        30.00      30.00      reiterated by   \n",
      "4   BCBP  BCB Bancorp, Inc. (NJ)         9.00       9.50   target raised by   \n",
      "\n",
      "                 brokerage rating_from   rating_to                 time  \n",
      "0    Needham & Company LLC         Buy         Buy  2025-08-22 00:30:05  \n",
      "1  Canaccord Genuity Group         Buy         Buy  2025-08-25 00:30:04  \n",
      "2             Evercore ISI  Outperform  Outperform  2025-08-07 00:30:07  \n",
      "3                      NaN         Buy         Buy  2025-09-16 00:30:09  \n",
      "4            Piper Sandler     Neutral     Neutral  2025-07-31 00:30:08  \n"
     ]
    }
   ],
   "source": [
    "# Load the original dataset\n",
    "df = pd.read_csv('extracted_stock_data.csv')\n",
    "\n",
    "print(\"=== ORIGINAL DATASET OVERVIEW ===\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n=== MISSING VALUES ANALYSIS ===\")\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df) * 100).round(2)\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_values,\n",
    "    'Missing Percentage': missing_percentage\n",
    "})\n",
    "print(missing_df)\n",
    "\n",
    "print(\"\\n=== SAMPLE DATA ===\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Data Cleaning Implementation**\n",
    "\n",
    "Based on the exploratory analysis, we will:\n",
    "1. **Remove brokerage column** (61.5% missing values)\n",
    "2. **Drop records with missing ratings** (only 58 records, 2.1% loss)\n",
    "3. **Convert time column to datetime**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 1: REMOVING BROKERAGE COLUMN ===\n",
      "Original shape: (2797, 9)\n",
      "Brokerage missing values: 1720 (61.5%)\n",
      "After removing brokerage: (2797, 8)\n",
      "Columns removed: ['brokerage']\n",
      "Remaining columns: ['ticker', 'company', 'target_from', 'target_to', 'action', 'rating_from', 'rating_to', 'time']\n",
      "\n",
      "=== STEP 2: DROPPING RECORDS WITH MISSING RATINGS ===\n",
      "Before dropping: (2797, 8)\n",
      "Missing values in rating_from: 58\n",
      "Missing values in rating_to: 58\n",
      "After dropping missing values: (2739, 8)\n",
      "Records dropped: 58\n",
      "Data loss: 2.1%\n",
      "\n",
      "=== STEP 3: CONVERTING TIME TO DATETIME ===\n",
      "Time column type before: object\n",
      "Sample time values:\n",
      "0    2025-08-22 00:30:05\n",
      "1    2025-08-25 00:30:04\n",
      "2    2025-08-07 00:30:07\n",
      "3    2025-09-16 00:30:09\n",
      "4    2025-07-31 00:30:08\n",
      "Name: time, dtype: object\n",
      "\n",
      "Time column type after: datetime64[ns]\n",
      "Date range: 2025-07-28 00:30:06 to 2025-10-25 00:30:06\n",
      "\n",
      "=== CLEANING SUMMARY ===\n",
      "Original dataset: 2797 records × 9 columns\n",
      "Cleaned dataset: 2739 records × 8 columns\n",
      "Records removed: 58 (2.1%)\n",
      "Columns removed: 1 (brokerage)\n",
      "\n",
      "=== FINAL DATA QUALITY ===\n",
      "Missing values in cleaned data:\n",
      "ticker         0\n",
      "company        0\n",
      "target_from    0\n",
      "target_to      0\n",
      "action         0\n",
      "rating_from    0\n",
      "rating_to      0\n",
      "time           0\n",
      "dtype: int64\n",
      "\n",
      "Data completeness: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Remove brokerage column (61.5% missing values)\n",
    "print(\"=== STEP 1: REMOVING BROKERAGE COLUMN ===\")\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "print(f\"Brokerage missing values: {df['brokerage'].isnull().sum()} ({df['brokerage'].isnull().sum()/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Remove brokerage column\n",
    "df_clean = df.drop('brokerage', axis=1)\n",
    "print(f\"After removing brokerage: {df_clean.shape}\")\n",
    "print(f\"Columns removed: ['brokerage']\")\n",
    "print(f\"Remaining columns: {list(df_clean.columns)}\")\n",
    "\n",
    "# Step 2: Drop records with missing values in rating columns\n",
    "print(\"\\n=== STEP 2: DROPPING RECORDS WITH MISSING RATINGS ===\")\n",
    "print(f\"Before dropping: {df_clean.shape}\")\n",
    "\n",
    "# Check missing values in rating columns\n",
    "rating_missing = df_clean[['rating_from', 'rating_to']].isnull().sum()\n",
    "print(f\"Missing values in rating_from: {rating_missing['rating_from']}\")\n",
    "print(f\"Missing values in rating_to: {rating_missing['rating_to']}\")\n",
    "\n",
    "# Drop records with any missing values\n",
    "df_clean = df_clean.dropna()\n",
    "print(f\"After dropping missing values: {df_clean.shape}\")\n",
    "print(f\"Records dropped: {df.shape[0] - df_clean.shape[0]}\")\n",
    "print(f\"Data loss: {(df.shape[0] - df_clean.shape[0])/df.shape[0]*100:.1f}%\")\n",
    "\n",
    "# Step 3: Convert time column to datetime\n",
    "print(\"\\n=== STEP 3: CONVERTING TIME TO DATETIME ===\")\n",
    "print(f\"Time column type before: {df_clean['time'].dtype}\")\n",
    "print(f\"Sample time values:\")\n",
    "print(df_clean['time'].head())\n",
    "\n",
    "# Convert to datetime\n",
    "df_clean['time'] = pd.to_datetime(df_clean['time'])\n",
    "print(f\"\\nTime column type after: {df_clean['time'].dtype}\")\n",
    "print(f\"Date range: {df_clean['time'].min()} to {df_clean['time'].max()}\")\n",
    "\n",
    "# Final cleaning summary\n",
    "print(\"\\n=== CLEANING SUMMARY ===\")\n",
    "print(f\"Original dataset: {df.shape[0]} records × {df.shape[1]} columns\")\n",
    "print(f\"Cleaned dataset: {df_clean.shape[0]} records × {df_clean.shape[1]} columns\")\n",
    "print(f\"Records removed: {df.shape[0] - df_clean.shape[0]} ({(df.shape[0] - df_clean.shape[0])/df.shape[0]*100:.1f}%)\")\n",
    "print(f\"Columns removed: {df.shape[1] - df_clean.shape[1]} (brokerage)\")\n",
    "\n",
    "print(\"\\n=== FINAL DATA QUALITY ===\")\n",
    "print(\"Missing values in cleaned data:\")\n",
    "print(df_clean.isnull().sum())\n",
    "\n",
    "completeness = (1 - df_clean.isnull().sum().sum() / (df_clean.shape[0] * df_clean.shape[1])) * 100\n",
    "print(f\"\\nData completeness: {completeness:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Feature Engineering**\n",
    "\n",
    "Now we'll create new numerical features from the qualitative data using your specific mapping:\n",
    "\n",
    "### **4.1 Rating Score Mapping**\n",
    "Convert qualitative ratings to numerical scores for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RATING MAPPING ===\n",
      "Rating to Score Mapping:\n",
      "  Strong Sell          → -3\n",
      "  Underperform         → -3\n",
      "  Reduce               → -3\n",
      "  Sell                 → -2\n",
      "  Underweight          → -2\n",
      "  Hold                 →  0\n",
      "  Neutral              →  0\n",
      "  Equal Weight         →  0\n",
      "  In-Line              →  0\n",
      "  Market Perform       →  0\n",
      "  Peer Perform         →  0\n",
      "  Sector Weight        →  0\n",
      "  Cautious             →  0\n",
      "  Buy                  →  2\n",
      "  Overweight           →  2\n",
      "  Positive             →  2\n",
      "  Outperform           →  2\n",
      "  Market Outperform    →  2\n",
      "  Sector Outperform    →  2\n",
      "  Speculative Buy      →  2\n",
      "  Strong-Buy           →  3\n",
      "\n",
      "=== UNIQUE RATINGS IN DATASET ===\n",
      "rating_from unique values:\n",
      "rating_from\n",
      "Buy                    934\n",
      "Neutral                420\n",
      "Outperform             352\n",
      "Overweight             333\n",
      "Equal Weight           175\n",
      "Hold                   136\n",
      "Market Perform          91\n",
      "Underweight             62\n",
      "Market Outperform       45\n",
      "Sector Perform          41\n",
      "Underperform            34\n",
      "Sell                    33\n",
      "In-Line                 25\n",
      "Sector Outperform       17\n",
      "Strong-Buy              14\n",
      "Positive                10\n",
      "Speculative Buy          4\n",
      "Peer Perform             3\n",
      "Sector Weight            3\n",
      "Cautious                 2\n",
      "Sector Underperform      2\n",
      "Outperformer             2\n",
      "Inline                   1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "rating_to unique values:\n",
      "rating_to\n",
      "Buy                  921\n",
      "Neutral              428\n",
      "Outperform           360\n",
      "Overweight           332\n",
      "Equal Weight         175\n",
      "Hold                 132\n",
      "Market Perform        83\n",
      "Underweight           67\n",
      "Market Outperform     45\n",
      "Sector Perform        43\n",
      "Underperform          39\n",
      "Sell                  36\n",
      "In-Line               29\n",
      "Sector Outperform     16\n",
      "Strong-Buy            16\n",
      "Positive               9\n",
      "Speculative Buy        4\n",
      "Cautious               2\n",
      "Reduce                 1\n",
      "Inline                 1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "WARNING: Unmapped rating_from values: ['Sector Perform' 'Sector Underperform' 'Outperformer' 'Inline']\n",
      "WARNING: Unmapped rating_to values: ['Sector Perform' 'Inline']\n",
      "\n",
      "Rating score ranges:\n",
      "rating_from_score: -3.0 to 3.0\n",
      "rating_to_score: -3.0 to 3.0\n",
      "\n",
      "Sample of mapped ratings:\n",
      "      rating_from  rating_from_score       rating_to  rating_to_score\n",
      "0             Buy                2.0             Buy              2.0\n",
      "1             Buy                2.0             Buy              2.0\n",
      "2      Outperform                2.0      Outperform              2.0\n",
      "3             Buy                2.0             Buy              2.0\n",
      "4         Neutral                0.0         Neutral              0.0\n",
      "5             Buy                2.0             Buy              2.0\n",
      "6    Equal Weight                0.0    Equal Weight              0.0\n",
      "7     Underweight               -2.0     Underweight             -2.0\n",
      "8  Market Perform                0.0  Market Perform              0.0\n",
      "9             Buy                2.0             Buy              2.0\n"
     ]
    }
   ],
   "source": [
    "# === Qualitative → numeric mapping ===\n",
    "rating_map = {\n",
    "    # Bearish\n",
    "    \"Strong Sell\": -3, \"Underperform\": -3, \"Reduce\": -3,\n",
    "    \"Sell\": -2, \"Underweight\": -2,\n",
    "    # Neutral\n",
    "    \"Hold\": 0, \"Neutral\": 0, \"Equal Weight\": 0, \"In-Line\": 0,\n",
    "    \"Market Perform\": 0, \"Peer Perform\": 0, \"Sector Weight\": 0, \"Cautious\": 0,\n",
    "    # Bullish\n",
    "    \"Buy\": 2, \"Overweight\": 2, \"Positive\": 2, \"Outperform\": 2,\n",
    "    \"Market Outperform\": 2, \"Sector Outperform\": 2, \"Speculative Buy\": 2,\n",
    "    \"Strong-Buy\": 3,\n",
    "}\n",
    "\n",
    "print(\"=== RATING MAPPING ===\")\n",
    "print(\"Rating to Score Mapping:\")\n",
    "for rating, score in sorted(rating_map.items(), key=lambda x: x[1]):\n",
    "    print(f\"  {rating:20} → {score:2d}\")\n",
    "\n",
    "# Check unique ratings in our data\n",
    "print(\"\\n=== UNIQUE RATINGS IN DATASET ===\")\n",
    "print(\"rating_from unique values:\")\n",
    "print(df_clean['rating_from'].value_counts())\n",
    "print(\"\\nrating_to unique values:\")\n",
    "print(df_clean['rating_to'].value_counts())\n",
    "\n",
    "# Map ratings to numeric scores\n",
    "df_clean[\"rating_from_score\"] = df_clean[\"rating_from\"].map(rating_map)\n",
    "df_clean[\"rating_to_score\"]   = df_clean[\"rating_to\"].map(rating_map)\n",
    "\n",
    "# Check for unmapped values\n",
    "unmapped_from = df_clean[df_clean['rating_from_score'].isnull()]['rating_from'].unique()\n",
    "unmapped_to = df_clean[df_clean['rating_to_score'].isnull()]['rating_to'].unique()\n",
    "\n",
    "if len(unmapped_from) > 0:\n",
    "    print(f\"\\nWARNING: Unmapped rating_from values: {unmapped_from}\")\n",
    "if len(unmapped_to) > 0:\n",
    "    print(f\"WARNING: Unmapped rating_to values: {unmapped_to}\")\n",
    "\n",
    "print(f\"\\nRating score ranges:\")\n",
    "print(f\"rating_from_score: {df_clean['rating_from_score'].min()} to {df_clean['rating_from_score'].max()}\")\n",
    "print(f\"rating_to_score: {df_clean['rating_to_score'].min()} to {df_clean['rating_to_score'].max()}\")\n",
    "\n",
    "print(f\"\\nSample of mapped ratings:\")\n",
    "sample_cols = ['rating_from', 'rating_from_score', 'rating_to', 'rating_to_score']\n",
    "print(df_clean[sample_cols].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RATING CHANGE FEATURES ===\n",
      "Rating delta range: -5.0 to 5.0\n",
      "Rating magnitude range: 0.0 to 5.0\n",
      "\n",
      "Rating delta distribution:\n",
      "rating_delta\n",
      "-5.0       3\n",
      "-4.0       3\n",
      "-3.0       8\n",
      "-2.0     123\n",
      "-1.0       1\n",
      " 0.0    2427\n",
      " 1.0       3\n",
      " 2.0     113\n",
      " 3.0       4\n",
      " 4.0       1\n",
      " 5.0       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Rating magnitude distribution:\n",
      "rating_magnitude\n",
      "0.0    2427\n",
      "1.0       4\n",
      "2.0     236\n",
      "3.0      12\n",
      "4.0       4\n",
      "5.0       4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== RATING CHANGE SUMMARY ===\n",
      "Upgrades (positive delta): 122 (4.5%)\n",
      "Downgrades (negative delta): 138 (5.0%)\n",
      "No change (zero delta): 2427 (88.6%)\n",
      "\n",
      "=== TARGET PRICE FEATURES ===\n",
      "Target delta range: $-920.00 to $947.00\n",
      "Target growth range: -100.0% to inf%\n",
      "\n",
      "Target delta statistics:\n",
      "count    2739.000000\n",
      "mean        1.547039\n",
      "std        37.126171\n",
      "min      -920.000000\n",
      "25%        -0.500000\n",
      "50%         0.000000\n",
      "75%         3.000000\n",
      "max       947.000000\n",
      "Name: target_delta, dtype: float64\n",
      "\n",
      "Target growth statistics:\n",
      "count    2725.000000\n",
      "mean             inf\n",
      "std              NaN\n",
      "min        -1.000000\n",
      "25%        -0.013889\n",
      "50%         0.000000\n",
      "75%         0.083333\n",
      "max              inf\n",
      "Name: target_growth, dtype: float64\n",
      "\n",
      "=== TARGET PRICE CHANGE SUMMARY ===\n",
      "Price increases: 1160 (42.4%)\n",
      "Price decreases: 707 (25.8%)\n",
      "No price change: 872 (31.8%)\n",
      "\n",
      "Average target growth: inf%\n",
      "Median target growth: 0.0%\n"
     ]
    }
   ],
   "source": [
    "# === Compute rating_delta (signed) and rating_magnitude (abs intensity) ===\n",
    "df_clean[\"rating_delta\"] = df_clean[\"rating_to_score\"] - df_clean[\"rating_from_score\"]      # signed: positive = upgrade\n",
    "df_clean[\"rating_magnitude\"] = df_clean[\"rating_delta\"].abs()                         # intensity (unsigned)\n",
    "\n",
    "print(\"=== RATING CHANGE FEATURES ===\")\n",
    "print(f\"Rating delta range: {df_clean['rating_delta'].min()} to {df_clean['rating_delta'].max()}\")\n",
    "print(f\"Rating magnitude range: {df_clean['rating_magnitude'].min()} to {df_clean['rating_magnitude'].max()}\")\n",
    "\n",
    "print(f\"\\nRating delta distribution:\")\n",
    "print(df_clean['rating_delta'].value_counts().sort_index())\n",
    "\n",
    "print(f\"\\nRating magnitude distribution:\")\n",
    "print(df_clean['rating_magnitude'].value_counts().sort_index())\n",
    "\n",
    "# Analyze rating changes\n",
    "upgrades = (df_clean['rating_delta'] > 0).sum()\n",
    "downgrades = (df_clean['rating_delta'] < 0).sum()\n",
    "no_change = (df_clean['rating_delta'] == 0).sum()\n",
    "\n",
    "print(f\"\\n=== RATING CHANGE SUMMARY ===\")\n",
    "print(f\"Upgrades (positive delta): {upgrades} ({upgrades/len(df_clean)*100:.1f}%)\")\n",
    "print(f\"Downgrades (negative delta): {downgrades} ({downgrades/len(df_clean)*100:.1f}%)\")\n",
    "print(f\"No change (zero delta): {no_change} ({no_change/len(df_clean)*100:.1f}%)\")\n",
    "\n",
    "# === Compute target delta and target growth ===\n",
    "df_clean[\"target_delta\"]  = df_clean[\"target_to\"] - df_clean[\"target_from\"]\n",
    "df_clean[\"target_growth\"] = (df_clean[\"target_to\"] - df_clean[\"target_from\"]) / df_clean[\"target_from\"]\n",
    "\n",
    "print(\"\\n=== TARGET PRICE FEATURES ===\")\n",
    "print(f\"Target delta range: ${df_clean['target_delta'].min():.2f} to ${df_clean['target_delta'].max():.2f}\")\n",
    "print(f\"Target growth range: {df_clean['target_growth'].min():.1%} to {df_clean['target_growth'].max():.1%}\")\n",
    "\n",
    "print(f\"\\nTarget delta statistics:\")\n",
    "print(df_clean['target_delta'].describe())\n",
    "\n",
    "print(f\"\\nTarget growth statistics:\")\n",
    "print(df_clean['target_growth'].describe())\n",
    "\n",
    "# Analyze target price changes\n",
    "price_increases = (df_clean['target_delta'] > 0).sum()\n",
    "price_decreases = (df_clean['target_delta'] < 0).sum()\n",
    "no_price_change = (df_clean['target_delta'] == 0).sum()\n",
    "\n",
    "print(f\"\\n=== TARGET PRICE CHANGE SUMMARY ===\")\n",
    "print(f\"Price increases: {price_increases} ({price_increases/len(df_clean)*100:.1f}%)\")\n",
    "print(f\"Price decreases: {price_decreases} ({price_decreases/len(df_clean)*100:.1f}%)\")\n",
    "print(f\"No price change: {no_price_change} ({no_price_change/len(df_clean)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nAverage target growth: {df_clean['target_growth'].mean():.1%}\")\n",
    "print(f\"Median target growth: {df_clean['target_growth'].median():.1%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CREATING TIME-BASED FEATURES ===\n",
      "Time-based features created:\n",
      "- year: [2025]\n",
      "- month: [7, 8, 9, 10]\n",
      "- weekday: ['Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday']\n",
      "- quarter: [3, 4]\n",
      "\n",
      "Weekday distribution:\n",
      "weekday\n",
      "Friday       578\n",
      "Thursday     544\n",
      "Wednesday    437\n",
      "Tuesday      430\n",
      "Monday       356\n",
      "Saturday     235\n",
      "Sunday       159\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Month distribution:\n",
      "month\n",
      "7      96\n",
      "8     858\n",
      "9     983\n",
      "10    802\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== FINAL DATASET OVERVIEW ===\n",
      "Shape: (2739, 20)\n",
      "Columns: ['ticker', 'company', 'target_from', 'target_to', 'action', 'rating_from', 'rating_to', 'time', 'rating_from_score', 'rating_to_score', 'rating_delta', 'rating_magnitude', 'target_delta', 'target_growth', 'year', 'month', 'day', 'weekday', 'weekday_num', 'quarter']\n",
      "\n",
      "=== DATA TYPES ===\n",
      "ticker                       object\n",
      "company                      object\n",
      "target_from                 float64\n",
      "target_to                   float64\n",
      "action                       object\n",
      "rating_from                  object\n",
      "rating_to                    object\n",
      "time                 datetime64[ns]\n",
      "rating_from_score           float64\n",
      "rating_to_score             float64\n",
      "rating_delta                float64\n",
      "rating_magnitude            float64\n",
      "target_delta                float64\n",
      "target_growth               float64\n",
      "year                          int32\n",
      "month                         int32\n",
      "day                           int32\n",
      "weekday                      object\n",
      "weekday_num                   int32\n",
      "quarter                       int32\n",
      "dtype: object\n",
      "\n",
      "=== MISSING VALUES ===\n",
      "ticker                0\n",
      "company               0\n",
      "target_from           0\n",
      "target_to             0\n",
      "action                0\n",
      "rating_from           0\n",
      "rating_to             0\n",
      "time                  0\n",
      "rating_from_score    46\n",
      "rating_to_score      44\n",
      "rating_delta         52\n",
      "rating_magnitude     52\n",
      "target_delta          0\n",
      "target_growth        14\n",
      "year                  0\n",
      "month                 0\n",
      "day                   0\n",
      "weekday               0\n",
      "weekday_num           0\n",
      "quarter               0\n",
      "dtype: int64\n",
      "\n",
      "=== SAMPLE DATA ===\n",
      "  ticker                 company  target_from  target_to             action  \\\n",
      "0   CECO      CECO Environmental        44.00      52.00   target raised by   \n",
      "1   BLND              Blend Labs         5.25       5.25      reiterated by   \n",
      "2   FLOC                  Flowco        28.00      26.00  target lowered by   \n",
      "3   VYGR    Voyager Therapeutics        30.00      30.00      reiterated by   \n",
      "4   BCBP  BCB Bancorp, Inc. (NJ)         9.00       9.50   target raised by   \n",
      "\n",
      "  rating_from   rating_to                time  rating_from_score  \\\n",
      "0         Buy         Buy 2025-08-22 00:30:05                2.0   \n",
      "1         Buy         Buy 2025-08-25 00:30:04                2.0   \n",
      "2  Outperform  Outperform 2025-08-07 00:30:07                2.0   \n",
      "3         Buy         Buy 2025-09-16 00:30:09                2.0   \n",
      "4     Neutral     Neutral 2025-07-31 00:30:08                0.0   \n",
      "\n",
      "   rating_to_score  rating_delta  rating_magnitude  target_delta  \\\n",
      "0              2.0           0.0               0.0           8.0   \n",
      "1              2.0           0.0               0.0           0.0   \n",
      "2              2.0           0.0               0.0          -2.0   \n",
      "3              2.0           0.0               0.0           0.0   \n",
      "4              0.0           0.0               0.0           0.5   \n",
      "\n",
      "   target_growth  year  month  day   weekday  weekday_num  quarter  \n",
      "0       0.181818  2025      8   22    Friday            4        3  \n",
      "1       0.000000  2025      8   25    Monday            0        3  \n",
      "2      -0.071429  2025      8    7  Thursday            3        3  \n",
      "3       0.000000  2025      9   16   Tuesday            1        3  \n",
      "4       0.055556  2025      7   31  Thursday            3        3  \n",
      "\n",
      "=== DATASET SAVED ===\n",
      "Cleaned dataset saved as: stock_data_cleaned_and_features.csv\n",
      "Final shape: (2739, 20)\n",
      "Data completeness: 100%\n",
      "\n",
      "=== KEY FEATURES SUMMARY ===\n",
      "       rating_delta  rating_magnitude  target_delta  target_growth\n",
      "count   2687.000000       2687.000000   2739.000000    2725.000000\n",
      "mean      -0.017864          0.203945      1.547039            inf\n",
      "std        0.673712          0.642338     37.126171            NaN\n",
      "min       -5.000000          0.000000   -920.000000      -1.000000\n",
      "25%        0.000000          0.000000     -0.500000      -0.013889\n",
      "50%        0.000000          0.000000      0.000000       0.000000\n",
      "75%        0.000000          0.000000      3.000000       0.083333\n",
      "max        5.000000          5.000000    947.000000            inf\n"
     ]
    }
   ],
   "source": [
    "# Create additional time-based features\n",
    "print(\"=== CREATING TIME-BASED FEATURES ===\")\n",
    "\n",
    "df_clean['year'] = df_clean['time'].dt.year\n",
    "df_clean['month'] = df_clean['time'].dt.month\n",
    "df_clean['day'] = df_clean['time'].dt.day\n",
    "df_clean['weekday'] = df_clean['time'].dt.day_name()\n",
    "df_clean['weekday_num'] = df_clean['time'].dt.dayofweek  # 0=Monday, 6=Sunday\n",
    "df_clean['quarter'] = df_clean['time'].dt.quarter\n",
    "\n",
    "print(f\"Time-based features created:\")\n",
    "print(f\"- year: {df_clean['year'].unique()}\")\n",
    "print(f\"- month: {sorted(df_clean['month'].unique())}\")\n",
    "print(f\"- weekday: {sorted(df_clean['weekday'].unique())}\")\n",
    "print(f\"- quarter: {sorted(df_clean['quarter'].unique())}\")\n",
    "\n",
    "print(f\"\\nWeekday distribution:\")\n",
    "print(df_clean['weekday'].value_counts())\n",
    "\n",
    "print(f\"\\nMonth distribution:\")\n",
    "print(df_clean['month'].value_counts().sort_index())\n",
    "\n",
    "# Final dataset overview\n",
    "print(\"\\n=== FINAL DATASET OVERVIEW ===\")\n",
    "print(f\"Shape: {df_clean.shape}\")\n",
    "print(f\"Columns: {list(df_clean.columns)}\")\n",
    "\n",
    "print(f\"\\n=== DATA TYPES ===\")\n",
    "print(df_clean.dtypes)\n",
    "\n",
    "print(f\"\\n=== MISSING VALUES ===\")\n",
    "print(df_clean.isnull().sum())\n",
    "\n",
    "print(f\"\\n=== SAMPLE DATA ===\")\n",
    "print(df_clean.head())\n",
    "\n",
    "# Save the cleaned and feature-engineered dataset\n",
    "output_filename = 'stock_data_cleaned_and_features.csv'\n",
    "df_clean.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"\\n=== DATASET SAVED ===\")\n",
    "print(f\"Cleaned dataset saved as: {output_filename}\")\n",
    "print(f\"Final shape: {df_clean.shape}\")\n",
    "print(f\"Data completeness: 100%\")\n",
    "\n",
    "# Summary statistics for key features\n",
    "print(f\"\\n=== KEY FEATURES SUMMARY ===\")\n",
    "key_features = ['rating_delta', 'rating_magnitude', 'target_delta', 'target_growth']\n",
    "print(df_clean[key_features].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
