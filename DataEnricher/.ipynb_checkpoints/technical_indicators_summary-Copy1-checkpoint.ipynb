{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Technical Indicators and Correlation Analysis Summary\n",
    "\n",
    "This notebook summarizes the technical indicators integration and correlation analysis for feature reduction.\n",
    "\n",
    "## Overview\n",
    "The dataset is enriched with technical indicators from Yahoo Finance, then analyzed for correlations to reduce dimensionality and multicollinearity.\n",
    "\n",
    "## Data Sources\n",
    "- **Cleaned Dataset**: `stock_data_cleaned_and_features.csv` - Processed data with engineered features\n",
    "- **Technical Indicators**: `stock_data_with_technical_indicators.csv` - Data with technical indicators\n",
    "- **Process**: Load → Merge → Null Analysis → Drop High Null Columns → Drop Null Rows → Eliminate Inf/NaN → Correlation Analysis → Feature Reduction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Merge Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned dataset with engineered features\n",
    "df_clean = pd.read_csv('stock_data_cleaned_and_features.csv')\n",
    "print(f\"Cleaned dataset shape: {df_clean.shape}\")\n",
    "\n",
    "# Load technical indicators dataset\n",
    "df_indicators = pd.read_csv('stock_data_with_technical_indicators.csv')\n",
    "print(f\"Technical indicators dataset shape: {df_indicators.shape}\")\n",
    "\n",
    "# Merge datasets on ticker\n",
    "df_merged = df_clean.merge(df_indicators, on='ticker', how='inner')\n",
    "print(f\"Merged dataset shape: {df_merged.shape}\")\n",
    "\n",
    "# Define technical indicators\n",
    "technical_indicators = [\n",
    "    'rsi', 'stoch', 'willr', 'roc', 'mom', 'rvi', 'cci',  # Momentum\n",
    "    'ema', 'sma', 'wma', 'hma', 'tema', 'dema', 'vwma', 'kama', 'swma', 'fwma', 'hwma',  # Trend\n",
    "    'atr', 'natr', 'bb_upper', 'bb_middle', 'bb_lower', 'bb_width',  # Volatility\n",
    "    'mfi', 'obv', 'ad', 'cmf', 'vwap', 'pvt', 'eom', 'nvi'  # Volume\n",
    "]\n",
    "\n",
    "print(f\"\\nTechnical indicators available: {len(technical_indicators)}\")\n",
    "print(f\"All columns in merged dataset: {list(df_merged.columns)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Null Value Analysis and Cleaning\n",
    "\n",
    "### 2.1 Drop High Null Columns (>10%) and Null Rows\n",
    "\n",
    "### 2.2 Eliminate Infinite and NaN Values\n",
    "After dropping high null columns and null rows, we need to handle any remaining infinite values that may cause issues in correlation analysis and clustering.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
