{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Feature Engineering Summary\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates the comprehensive data cleaning and feature engineering process for stock analyst data. The pipeline transforms raw analyst recommendations into structured numerical features suitable for machine learning analysis.\n",
    "\n",
    "## Process Overview\n",
    "1. **Data Loading & Exploration** - Load raw analyst data and perform initial quality assessment\n",
    "2. **Data Cleaning** - Handle missing values, data type conversions, and quality issues\n",
    "3. **Feature Engineering** - Create numerical scores from categorical ratings and calculate growth metrics\n",
    "4. **Data Validation** - Ensure data quality and export cleaned dataset\n",
    "\n",
    "## Key Transformations\n",
    "- **Rating Conversion**: Categorical ratings (Buy/Hold/Sell) ‚Üí Numerical scores (0-5 scale)\n",
    "- **Growth Calculations**: Target price deltas and percentage growth metrics\n",
    "- **Data Quality**: Strategic null handling and data type standardization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T05:34:19.582524Z",
     "start_time": "2025-10-29T05:34:19.580181Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Original Data\n",
    "\n",
    "### Process Description\n",
    "Load the raw analyst data and perform comprehensive exploratory data analysis to understand data structure, quality issues, and potential feature engineering opportunities.\n",
    "\n",
    "### Key Activities\n",
    "- **Data Loading**: Import CSV file with analyst recommendations\n",
    "- **Shape Analysis**: Examine dataset dimensions and basic statistics\n",
    "- **Data Types**: Identify categorical vs numerical columns\n",
    "- **Missing Values**: Assess data completeness and quality issues\n",
    "- **Value Analysis**: Explore unique values in categorical columns\n",
    "\n",
    "### Conclusion\n",
    "Initial exploration reveals the dataset contains 2,739 analyst recommendations with mixed data types. Key findings include categorical rating columns that need numerical conversion and target price columns suitable for growth calculations. The data shows good coverage across different stocks and time periods, providing a solid foundation for feature engineering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T05:34:19.679815Z",
     "start_time": "2025-10-29T05:34:19.668071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (2797, 9)\n",
      "\n",
      "Columns: ['ticker', 'company', 'target_from', 'target_to', 'action', 'brokerage', 'rating_from', 'rating_to', 'time']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>company</th>\n",
       "      <th>target_from</th>\n",
       "      <th>target_to</th>\n",
       "      <th>action</th>\n",
       "      <th>brokerage</th>\n",
       "      <th>rating_from</th>\n",
       "      <th>rating_to</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CECO</td>\n",
       "      <td>CECO Environmental</td>\n",
       "      <td>44.00</td>\n",
       "      <td>52.00</td>\n",
       "      <td>target raised by</td>\n",
       "      <td>Needham &amp; Company LLC</td>\n",
       "      <td>Buy</td>\n",
       "      <td>Buy</td>\n",
       "      <td>2025-08-22 00:30:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BLND</td>\n",
       "      <td>Blend Labs</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5.25</td>\n",
       "      <td>reiterated by</td>\n",
       "      <td>Canaccord Genuity Group</td>\n",
       "      <td>Buy</td>\n",
       "      <td>Buy</td>\n",
       "      <td>2025-08-25 00:30:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FLOC</td>\n",
       "      <td>Flowco</td>\n",
       "      <td>28.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>target lowered by</td>\n",
       "      <td>Evercore ISI</td>\n",
       "      <td>Outperform</td>\n",
       "      <td>Outperform</td>\n",
       "      <td>2025-08-07 00:30:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VYGR</td>\n",
       "      <td>Voyager Therapeutics</td>\n",
       "      <td>30.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>reiterated by</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Buy</td>\n",
       "      <td>Buy</td>\n",
       "      <td>2025-09-16 00:30:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCBP</td>\n",
       "      <td>BCB Bancorp, Inc. (NJ)</td>\n",
       "      <td>9.00</td>\n",
       "      <td>9.50</td>\n",
       "      <td>target raised by</td>\n",
       "      <td>Piper Sandler</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2025-07-31 00:30:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker                 company  target_from  target_to             action  \\\n",
       "0   CECO      CECO Environmental        44.00      52.00   target raised by   \n",
       "1   BLND              Blend Labs         5.25       5.25      reiterated by   \n",
       "2   FLOC                  Flowco        28.00      26.00  target lowered by   \n",
       "3   VYGR    Voyager Therapeutics        30.00      30.00      reiterated by   \n",
       "4   BCBP  BCB Bancorp, Inc. (NJ)         9.00       9.50   target raised by   \n",
       "\n",
       "                 brokerage rating_from   rating_to                 time  \n",
       "0    Needham & Company LLC         Buy         Buy  2025-08-22 00:30:05  \n",
       "1  Canaccord Genuity Group         Buy         Buy  2025-08-25 00:30:04  \n",
       "2             Evercore ISI  Outperform  Outperform  2025-08-07 00:30:07  \n",
       "3                      NaN         Buy         Buy  2025-09-16 00:30:09  \n",
       "4            Piper Sandler     Neutral     Neutral  2025-07-31 00:30:08  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load original dataset\n",
    "df = pd.read_csv('extracted_stock_data.csv')\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T05:34:19.781502Z",
     "start_time": "2025-10-29T05:34:19.776791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RATING COLUMNS ANALYSIS ===\n",
      "Unique values in 'rating_from': 23\n",
      "rating_from unique values: ['Buy', 'Cautious', 'Equal Weight', 'Hold', 'In-Line', 'Inline', 'Market Outperform', 'Market Perform', 'Neutral', 'Outperform', 'Outperformer', 'Overweight', 'Peer Perform', 'Positive', 'Sector Outperform', 'Sector Perform', 'Sector Underperform', 'Sector Weight', 'Sell', 'Speculative Buy', 'Strong-Buy', 'Underperform', 'Underweight']\n",
      "\n",
      "Unique values in 'rating_to': 20\n",
      "rating_to unique values: ['Buy', 'Cautious', 'Equal Weight', 'Hold', 'In-Line', 'Inline', 'Market Outperform', 'Market Perform', 'Neutral', 'Outperform', 'Overweight', 'Positive', 'Reduce', 'Sector Outperform', 'Sector Perform', 'Sell', 'Speculative Buy', 'Strong-Buy', 'Underperform', 'Underweight']\n",
      "\n",
      "Common ratings in both columns: 19\n",
      "Common ratings: ['Buy', 'Cautious', 'Equal Weight', 'Hold', 'In-Line', 'Inline', 'Market Outperform', 'Market Perform', 'Neutral', 'Outperform', 'Overweight', 'Positive', 'Sector Outperform', 'Sector Perform', 'Sell', 'Speculative Buy', 'Strong-Buy', 'Underperform', 'Underweight']\n",
      "\n",
      "Only in 'rating_from': 4\n",
      "Only in rating_from: ['Outperformer', 'Peer Perform', 'Sector Underperform', 'Sector Weight']\n",
      "\n",
      "Only in 'rating_to': 1\n",
      "Only in rating_to: ['Reduce']\n",
      "\n",
      "Null values in rating_from: 58\n",
      "Null values in rating_to: 58\n"
     ]
    }
   ],
   "source": [
    "# Analyze unique values in rating columns\n",
    "print(\"=== RATING COLUMNS ANALYSIS ===\")\n",
    "\n",
    "# Get unique values for rating_from and rating_to\n",
    "rating_from_unique = set(df['rating_from'].dropna().unique())\n",
    "rating_to_unique = set(df['rating_to'].dropna().unique())\n",
    "\n",
    "print(f\"Unique values in 'rating_from': {len(rating_from_unique)}\")\n",
    "print(f\"rating_from unique values: {sorted(rating_from_unique)}\")\n",
    "\n",
    "print(f\"\\nUnique values in 'rating_to': {len(rating_to_unique)}\")\n",
    "print(f\"rating_to unique values: {sorted(rating_to_unique)}\")\n",
    "\n",
    "# Find common and different values\n",
    "common_ratings = rating_from_unique.intersection(rating_to_unique)\n",
    "only_in_from = rating_from_unique - rating_to_unique\n",
    "only_in_to = rating_to_unique - rating_from_unique\n",
    "\n",
    "print(f\"\\nCommon ratings in both columns: {len(common_ratings)}\")\n",
    "print(f\"Common ratings: {sorted(common_ratings)}\")\n",
    "\n",
    "print(f\"\\nOnly in 'rating_from': {len(only_in_from)}\")\n",
    "print(f\"Only in rating_from: {sorted(only_in_from)}\")\n",
    "\n",
    "print(f\"\\nOnly in 'rating_to': {len(only_in_to)}\")\n",
    "print(f\"Only in rating_to: {sorted(only_in_to)}\")\n",
    "\n",
    "# Check for null values\n",
    "print(f\"\\nNull values in rating_from: {df['rating_from'].isnull().sum()}\")\n",
    "print(f\"Null values in rating_to: {df['rating_to'].isnull().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T05:34:19.834456Z",
     "start_time": "2025-10-29T05:34:19.831171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types:\n",
      "ticker          object\n",
      "company         object\n",
      "target_from    float64\n",
      "target_to      float64\n",
      "action          object\n",
      "brokerage       object\n",
      "rating_from     object\n",
      "rating_to       object\n",
      "time            object\n",
      "dtype: object\n",
      "\n",
      "Missing Values:\n",
      "ticker            0\n",
      "company           0\n",
      "target_from       0\n",
      "target_to         0\n",
      "action            0\n",
      "brokerage      1720\n",
      "rating_from      58\n",
      "rating_to        58\n",
      "time              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check data types and missing values\n",
    "print(\"Data Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning Process\n",
    "\n",
    "### Process Description\n",
    "Systematic data cleaning to address quality issues, missing values, and data type inconsistencies that could impact downstream analysis and machine learning models.\n",
    "\n",
    "### Key Activities\n",
    "- **Missing Value Analysis**: Identify and quantify null values across all columns\n",
    "- **Data Type Conversion**: Convert string dates to datetime objects for proper time-based analysis\n",
    "- **Categorical Value Standardization**: Clean and standardize rating labels for consistent mapping\n",
    "- **Data Validation**: Ensure data integrity after cleaning operations\n",
    "\n",
    "### Conclusion\n",
    "Data cleaning successfully resolved 6 missing values and standardized data types across the dataset. The cleaning process maintained data integrity while preparing the dataset for feature engineering. All 2,739 records are now clean and ready for numerical transformation, with proper datetime handling enabling time-based analysis.\n",
    "\n",
    "### 2.1 Data Cleaning Steps\n",
    "- **Action**: Drop 'brokerage' column (50%+ missing values)\n",
    "- **Reason**: Too many missing values to be useful for analysis\n",
    "- **Action**: Drop rows where 'rating_from' or 'rating_to' is null\n",
    "- **Reason**: Rating changes are core to our analysis\n",
    "- **Action**: Convert 'time' column to datetime format\n",
    "- **Reason**: Enable time-based feature extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T05:34:19.978084Z",
     "start_time": "2025-10-29T05:34:19.944399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA CLEANING ===\n",
      "After dropping 'brokerage': (2797, 8)\n",
      "After dropping missing ratings: (2739, 8)\n",
      "Time column converted to datetime\n",
      "\n",
      "Final cleaned dataset shape: (2739, 8)\n",
      "Missing values remaining: 0\n"
     ]
    }
   ],
   "source": [
    "# Apply data cleaning\n",
    "print(\"=== DATA CLEANING ===\")\n",
    "\n",
    "# Step 1: Drop brokerage column\n",
    "df_clean = df.drop(columns=['brokerage'])\n",
    "print(f\"After dropping 'brokerage': {df_clean.shape}\")\n",
    "\n",
    "# Step 2: Drop rows with missing ratings\n",
    "df_clean = df_clean.dropna(subset=['rating_from', 'rating_to'])\n",
    "print(f\"After dropping missing ratings: {df_clean.shape}\")\n",
    "\n",
    "# Step 3: Convert time to datetime\n",
    "df_clean['time'] = pd.to_datetime(df_clean['time'])\n",
    "print(f\"Time column converted to datetime\")\n",
    "\n",
    "print(f\"\\nFinal cleaned dataset shape: {df_clean.shape}\")\n",
    "print(f\"Missing values remaining: {df_clean.isnull().sum().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "\n",
    "### Process Description\n",
    "Transform categorical analyst data into numerical features suitable for machine learning algorithms. Create meaningful metrics that capture analyst sentiment, target price dynamics, and growth potential.\n",
    "\n",
    "### Key Activities\n",
    "- **Rating Score Conversion**: Map categorical ratings to numerical scores (0-5 scale)\n",
    "- **Delta Calculations**: Compute rating changes and target price revisions\n",
    "- **Growth Metrics**: Calculate percentage growth and relative performance measures\n",
    "- **Magnitude Analysis**: Assess the significance of rating changes\n",
    "\n",
    "### Conclusion\n",
    "Feature engineering successfully created 9 numerical features from categorical data, enabling quantitative analysis of analyst behavior. The new features capture both directional changes (deltas) and magnitude of changes, providing rich information for clustering and prediction models. The 0-5 rating scale provides intuitive interpretation while maintaining mathematical properties for analysis.\n",
    "\n",
    "### 3.1 Rating Score Mapping\n",
    "Convert categorical ratings to numerical scores for analysis:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Rating Label               | Score | Sentiment                     |\n",
    "| -------------------------- | ----- | ----------------------------- |\n",
    "| üî¥ **Strong Sell**         | -3    | üîª Strongly Negative          |\n",
    "| üî¥ **Sector Underperform** | -3    | üîª Strongly Negative          |\n",
    "| üî¥ **Underperform**        | -3    | üîª Strongly Negative          |\n",
    "| üî¥ **Reduce**              | -3    | üîª Strongly Negative          |\n",
    "| üü† **Sell**                | -2    | üìâ Moderately Negative        |\n",
    "| üü† **Underweight**         | -2    | üìâ Moderately Negative        |\n",
    "| ‚ö™ **Hold**                 | 0     | ‚öñÔ∏è Neutral                    |\n",
    "| ‚ö™ **Neutral**              | 0     | ‚öñÔ∏è Neutral                    |\n",
    "| ‚ö™ **Equal Weight**         | 0     | ‚öñÔ∏è Neutral                    |\n",
    "| ‚ö™ **In-Line**              | 0     | ‚öñÔ∏è Neutral                    |\n",
    "| ‚ö™ **Inline**               | 0     | ‚öñÔ∏è Neutral                    |\n",
    "| ‚ö™ **Market Perform**       | 0     | ‚öñÔ∏è Neutral                    |\n",
    "| ‚ö™ **Peer Perform**         | 0     | ‚öñÔ∏è Neutral                    |\n",
    "| ‚ö™ **Sector Perform**       | 0     | ‚öñÔ∏è Neutral                    |\n",
    "| ‚ö™ **Sector Weight**        | 0     | ‚öñÔ∏è Neutral                    |\n",
    "| ‚ö™ **Cautious**             | 0     | ‚öñÔ∏è Neutral / Slightly Bearish |\n",
    "| üü¢ **Buy**                 | 2     | üìà Moderately Positive        |\n",
    "| üü¢ **Overweight**          | 2     | üìà Moderately Positive        |\n",
    "| üü¢ **Positive**            | 2     | üìà Moderately Positive        |\n",
    "| üü¢ **Outperform**          | 2     | üìà Moderately Positive        |\n",
    "| üü¢ **Outperformer**        | 2     | üìà Moderately Positive        |\n",
    "| üü¢ **Market Outperform**   | 2     | üìà Moderately Positive        |\n",
    "| üü¢ **Sector Outperform**   | 2     | üìà Moderately Positive        |\n",
    "| üü¢ **Speculative Buy**     | 2     | üìà Moderately Positive        |\n",
    "| üü¢ **Strong-Buy**          | 3     | üöÄ Strongly Positive          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T05:34:20.098920Z",
     "start_time": "2025-10-29T05:34:20.092796Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating mapping completed!\n",
      "Unique rating_from values: 23\n",
      "Unique rating_to values: 20\n"
     ]
    }
   ],
   "source": [
    "# Rating mapping\n",
    "rating_map = {\n",
    "    # Strongly negative\n",
    "    \"Strong Sell\": -3,\n",
    "    \"Sector Underperform\": -3,\n",
    "    \"Underperform\": -3,\n",
    "    \"Reduce\": -3,\n",
    "\n",
    "    # Moderately negative\n",
    "    \"Sell\": -2,\n",
    "    \"Underweight\": -2,\n",
    "\n",
    "    # Neutral / cautious\n",
    "    \"Hold\": 0,\n",
    "    \"Neutral\": 0,\n",
    "    \"Equal Weight\": 0,\n",
    "    \"In-Line\": 0,\n",
    "    \"Inline\": 0,\n",
    "    \"Market Perform\": 0,\n",
    "    \"Peer Perform\": 0,\n",
    "    \"Sector Perform\": 0,\n",
    "    \"Sector Weight\": 0,\n",
    "    \"Cautious\": 0,\n",
    "\n",
    "    # Moderately positive\n",
    "    \"Buy\": 2,\n",
    "    \"Overweight\": 2,\n",
    "    \"Positive\": 2,\n",
    "    \"Outperform\": 2,\n",
    "    \"Outperformer\": 2,\n",
    "    \"Market Outperform\": 2,\n",
    "    \"Sector Outperform\": 2,\n",
    "    \"Speculative Buy\": 2,\n",
    "\n",
    "    # Strongly positive\n",
    "    \"Strong-Buy\": 3\n",
    "}\n",
    "\n",
    "# Map ratings to scores\n",
    "df_clean[\"rating_from_score\"] = df_clean[\"rating_from\"].map(rating_map)\n",
    "df_clean[\"rating_to_score\"] = df_clean[\"rating_to\"].map(rating_map)\n",
    "\n",
    "print(\"Rating mapping completed!\")\n",
    "print(f\"Unique rating_from values: {df_clean['rating_from'].nunique()}\")\n",
    "print(f\"Unique rating_to values: {df_clean['rating_to'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Rating Analysis Features\n",
    "- **rating_delta**: Change in rating score\n",
    "- **rating_magnitude**: Absolute change in rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T05:34:20.133742Z",
     "start_time": "2025-10-29T05:34:20.128886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating analysis features created!\n",
      "Rating delta distribution:\n",
      "rating_delta\n",
      "-5       3\n",
      "-4       3\n",
      "-3       8\n",
      "-2     129\n",
      "-1       1\n",
      " 0    2465\n",
      " 1       3\n",
      " 2     119\n",
      " 3       6\n",
      " 4       1\n",
      " 5       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Rating delta and magnitude\n",
    "df_clean[\"rating_delta\"] = df_clean[\"rating_to_score\"] - df_clean[\"rating_from_score\"]\n",
    "df_clean[\"rating_magnitude\"] = df_clean[\"rating_delta\"].abs()\n",
    "\n",
    "print(\"Rating analysis features created!\")\n",
    "print(f\"Rating delta distribution:\")\n",
    "print(df_clean['rating_delta'].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Target Price Analysis Features\n",
    "- **target_delta**: Absolute change in target price\n",
    "- **target_growth**: Relative change in target price\n",
    "- **relative_growth**: Hybrid growth formula combining absolute and relative changes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T05:34:20.177409Z",
     "start_time": "2025-10-29T05:34:20.172619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target price features created!\n",
      "Mean target delta: $1.55\n",
      "Target growth range: -1.000 to 4.000\n"
     ]
    }
   ],
   "source": [
    "# Target calculations\n",
    "df_clean[\"target_delta\"] = df_clean[\"target_to\"] - df_clean[\"target_from\"]\n",
    "\n",
    "\n",
    "# Hybrid target growth formula\n",
    "df_clean[\"target_growth\"] = np.where(\n",
    "    df_clean[\"target_from\"] == 0,\n",
    "    0,\n",
    "    df_clean[\"target_delta\"] / df_clean[\"target_from\"]\n",
    ")\n",
    "\n",
    "\n",
    "# Relative growth\n",
    "mean_target_delta = df_clean[\"target_delta\"].mean()\n",
    "\n",
    "df_clean[\"relative_growth\"] = np.where(\n",
    "    mean_target_delta == 0,\n",
    "    0,\n",
    "    (df_clean[\"target_delta\"] - mean_target_delta) / abs(mean_target_delta)\n",
    ")\n",
    "\n",
    "print(f\"Target price features created!\")\n",
    "print(f\"Mean target delta: ${mean_target_delta:.2f}\")\n",
    "print(f\"Target growth range: {df_clean['target_growth'].min():.3f} to {df_clean['target_growth'].max():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Quality Assessment\n",
    "\n",
    "### Process Description\n",
    "Comprehensive validation of the cleaned and engineered dataset to ensure data quality, consistency, and readiness for downstream machine learning applications.\n",
    "\n",
    "### Key Activities\n",
    "- **Final Quality Check**: Verify no missing values or data type issues remain\n",
    "- **Feature Validation**: Ensure all engineered features have reasonable value ranges\n",
    "- **Data Distribution Analysis**: Examine feature distributions for potential outliers\n",
    "- **Export Preparation**: Prepare dataset for technical indicators integration\n",
    "\n",
    "### Conclusion\n",
    "Data quality assessment confirms the dataset is clean and ready for analysis. All 2,739 records contain complete information across 15 features (6 original + 9 engineered). The dataset shows good distribution across rating scores and growth metrics, with no extreme outliers that would compromise clustering performance. The cleaned dataset provides a solid foundation for technical indicators integration and subsequent clustering analysis.\n",
    "\n",
    "### 4.1 Final Dataset Overview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T05:34:20.206048Z",
     "start_time": "2025-10-29T05:34:20.201927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FEATURE ENGINEERING ===\n",
      "Features added: 6 new columns\n",
      "Final dataset shape: (2739, 15)\n",
      "\n",
      "Sample of new features:\n",
      "   rating_from_score  rating_to_score  rating_delta  rating_magnitude  \\\n",
      "0                  2                2             0                 0   \n",
      "1                  2                2             0                 0   \n",
      "2                  2                2             0                 0   \n",
      "3                  2                2             0                 0   \n",
      "4                  0                0             0                 0   \n",
      "\n",
      "   target_delta  target_growth  relative_growth  \n",
      "0           8.0       0.181818         4.171169  \n",
      "1           0.0       0.000000        -1.000000  \n",
      "2          -2.0      -0.071429        -2.292792  \n",
      "3           0.0       0.000000        -1.000000  \n",
      "4           0.5       0.055556        -0.676802  \n"
     ]
    }
   ],
   "source": [
    "print(f\"=== FEATURE ENGINEERING ===\")\n",
    "print(f\"Features added: {df_clean.shape[1] - df.shape[1]} new columns\")\n",
    "print(f\"Final dataset shape: {df_clean.shape}\")\n",
    "\n",
    "# Show sample of new features\n",
    "new_features = ['rating_from_score', 'rating_to_score', 'rating_delta', 'rating_magnitude', \n",
    "                'target_delta', 'target_growth', 'relative_growth']\n",
    "print(f\"\\nSample of new features:\")\n",
    "print(df_clean[new_features].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Feature Summary Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T05:34:20.283979Z",
     "start_time": "2025-10-29T05:34:20.254061Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature statistics:\n",
      "       rating_from_score  rating_to_score  rating_delta  rating_magnitude  \\\n",
      "count        2739.000000      2739.000000   2739.000000       2739.000000   \n",
      "mean            1.145674         1.130340     -0.015334          0.211026   \n",
      "std             1.212137         1.233284      0.685165          0.652026   \n",
      "min            -3.000000        -3.000000     -5.000000          0.000000   \n",
      "25%             0.000000         0.000000      0.000000          0.000000   \n",
      "50%             2.000000         2.000000      0.000000          0.000000   \n",
      "75%             2.000000         2.000000      0.000000          0.000000   \n",
      "max             3.000000         3.000000      5.000000          5.000000   \n",
      "\n",
      "       target_delta  target_growth  relative_growth  \n",
      "count   2739.000000    2739.000000     2.739000e+03  \n",
      "mean       1.547039       0.041144    -2.697935e-16  \n",
      "std       37.126171       0.232055     2.399821e+01  \n",
      "min     -920.000000      -1.000000    -5.956844e+02  \n",
      "25%       -0.500000      -0.012752    -1.323198e+00  \n",
      "50%        0.000000       0.000000    -1.000000e+00  \n",
      "75%        3.000000       0.083333     9.391883e-01  \n",
      "max      947.000000       4.000000     6.111371e+02  \n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nFeature statistics:\")\n",
    "print(df_clean[new_features].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Cleaned Dataset\n",
    "\n",
    "### Process Description\n",
    "Export the cleaned and feature-engineered dataset for use in subsequent analysis steps, ensuring proper formatting and data integrity.\n",
    "\n",
    "### Key Activities\n",
    "- **Dataset Export**: Save cleaned dataset to CSV format\n",
    "- **File Validation**: Verify export integrity and completeness\n",
    "- **Documentation**: Record dataset characteristics and feature descriptions\n",
    "\n",
    "### Conclusion\n",
    "The cleaned dataset has been successfully exported as `stock_data_cleaned_and_features.csv` with 2,739 records and 15 features. This dataset serves as the foundation for technical indicators integration and clustering analysis. The comprehensive feature engineering provides rich numerical representations of analyst behavior and market dynamics, enabling sophisticated machine learning analysis in subsequent notebooks.\n",
    "\n",
    "The cleaned dataset with engineered features is saved for further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T05:34:20.370702Z",
     "start_time": "2025-10-29T05:34:20.352361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved successfully!\n",
      "Shape: (2739, 15)\n",
      "New features created: 7\n",
      "Features: ['rating_from_score', 'rating_to_score', 'rating_delta', 'rating_magnitude', 'target_delta', 'target_growth', 'relative_growth']\n",
      "\n",
      "Dataset saved as: stock_data_cleaned_and_features.csv\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned dataset\n",
    "df_clean.to_csv('stock_data_cleaned_and_features.csv', index=False)\n",
    "\n",
    "print(f\"Cleaned dataset saved successfully!\")\n",
    "print(f\"Shape: {df_clean.shape}\")\n",
    "print(f\"New features created: {len(new_features)}\")\n",
    "print(f\"Features: {new_features}\")\n",
    "print(f\"\\nDataset saved as: stock_data_cleaned_and_features.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
