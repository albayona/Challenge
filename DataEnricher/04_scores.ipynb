{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd127b94-65d4-46c8-a285-4783d9536c06",
   "metadata": {},
   "source": [
    "# Feature Scoring and Buy Signal Analysis Summary\n",
    "\n",
    "## Overview\n",
    "This notebook implements a comprehensive scoring system that combines analyst ratings, technical indicators, and market dynamics into actionable buy signals. The system normalizes features across categories and generates final scores for investment decision support.\n",
    "\n",
    "## Process Overview\n",
    "1. **Data Integration** - Merge clustered data with technical indicators and analyst features\n",
    "2. **Feature Categorization** - Group features into logical categories (Analyst, Volatility, Volume, Price)\n",
    "3. **Normalization** - Scale all features to 0-10 range for consistent scoring\n",
    "4. **Category Scoring** - Calculate average scores for each feature category\n",
    "5. **Final Scoring** - Generate overall buy signal scores\n",
    "\n",
    "## Key Transformations\n",
    "- **Multi-Source Integration**: Combines analyst data, technical indicators, and clustering results\n",
    "- **Normalized Scoring**: All features scaled to 0-10 range for fair comparison\n",
    "- **Category-Based Analysis**: Four distinct scoring categories for comprehensive evaluation\n",
    "- **Buy Signal Generation**: Final scores ranging from 0-10 for investment decisions\n",
    "\n",
    "### Feature Buy Score Interpretation Table\n",
    "\n",
    "| **Category** | **Feature** | **Higher → Effect** | **Lower → Effect** | **Neutral → Effect** |\n",
    "|--------------|-------------|--------------------|--------------------|----------------------|\n",
    "| **Analyst Targets & Ratings** | target_from | Indicates stronger bullish expectations; analysts expect price appreciation. | Suggests conservative outlook or lower expected price gains. | Stable outlook; analysts expect minimal change in target. |\n",
    "| | rating_from_score | Reflects more favorable initial analyst opinion (e.g., “Buy”). | Reflects less favorable rating (e.g., “Sell”). | Indicates neutral stance or “Hold” recommendation. |\n",
    "| | rating_delta | Positive delta signals upgrade — improved analyst confidence. | Negative delta signals downgrade — reduced analyst confidence. | No change in rating; sentiment remains consistent. |\n",
    "| | target_delta | Positive delta indicates an upward revision of price target. | Negative delta suggests reduced growth expectations. | No change indicates stable analyst expectations. |\n",
    "| | target_growth | Higher percentage increase signals higher projected price appreciation. | Lower percentage change signals limited growth potential. | Minimal change implies steady valuation expectations. |\n",
    "| | relative_growth | Indicates stock outperforming peers or market benchmark. | Indicates underperformance compared to peers or market. | On-par with general market or peer performance. |\n",
    "| **Volatility & Range** | ATR (Average True Range) | Larger ATR = stronger volatility, potential breakouts. | Smaller ATR = low volatility, consolidation phase. | Stable periods often precede volatility expansion. |\n",
    "| | Standard Deviation (σ) | Higher σ = high volatility, large price dispersion. | Lower σ = low volatility, tight trading range. | Indicates equilibrium; neither strong movement nor contraction. |\n",
    "| | Ulcer Index (UL) | Higher UL = higher downside risk and drawdown magnitude. | Lower UL = stable or quick price recovery. | Stable price action; minimal drawdown risk. |\n",
    "| | Price Distance (PDIST) | High PDIST = large movement magnitude, strong momentum. | Low PDIST = small changes, sideways movement. | Near-zero values = minimal change; no clear trend. |\n",
    "| **Cumulative Volume / Flow** | OBV (On Balance Volume) | Rising OBV confirms accumulation and bullish trend. | Falling OBV confirms distribution and bearish trend. | Flat OBV suggests neutral or weak conviction. |\n",
    "| | AD Line (Accumulation/Distribution Line) | Rising line indicates accumulation and strong inflows. | Falling line indicates distribution or outflows. | Flat or diverging line signals possible reversal. |\n",
    "| | PVT (Price Volume Trend) | Rising PVT indicates strong volume-backed bullish momentum. | Falling PVT indicates selling pressure. | Flat PVT signals weak volume support for trend. |\n",
    "| | FI (Force Index) | High positive FI = strong upward price move with volume. | Low or negative FI = weak or bearish momentum. | Near-zero FI = indecisive or range-bound market. |\n",
    "| **Price Filters (Level Indicators)** | HLC3 ((High+Low+Close)/3) | Indicates rising average price — strong uptrend. | Indicates falling average price — downtrend. | Price consolidating near average; sideways movement. |\n",
    "| | Typical Price (TP) | Higher TP = upward trend, higher average price. | Lower TP = downward trend, lower average price. | Price oscillating near average, indicating neutrality. |\n",
    "| | VWAP (Volume-Weighted Average Price) | Price above VWAP = strong buying pressure, bullish zone. | Price below VWAP = selling pressure, bearish zone. | Price at VWAP = equilibrium, fair market value. |\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "c8e9b5c2-34cf-4dba-a404-9916d976e5f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T06:09:50.762527Z",
     "start_time": "2025-11-02T06:09:50.547464Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 1 Load all CSV files\n",
    "df_clustered = pd.read_csv(\"stock_data_clustered_minmax4.csv\")\n",
    "df_indicators = pd.read_csv(\"stock_data_with_technical_indicators3.csv\")\n",
    "df_cleaned = pd.read_csv(\"stock_data_cleaned_and_features.csv\")\n",
    "\n",
    "# 2 Merge all three on common columns (ticker + date recommended)\n",
    "#    Avoid duplicate columns by removing repeated ones before merging\n",
    "def merge_unique(df_left, df_right, on=[\"ticker\", \"date\"]):\n",
    "    common_cols = list(set(df_left.columns) & set(df_right.columns))  # common columns\n",
    "    merge_keys = [k for k in on if k in common_cols]  # ensure merge keys exist\n",
    "    right_unique = df_right.drop(columns=[c for c in df_right.columns if c in df_left.columns and c not in merge_keys])\n",
    "    return pd.merge(df_left, right_unique, on=merge_keys, how=\"inner\")\n",
    "\n",
    "df = merge_unique(df_clustered, df_indicators)\n",
    "df = merge_unique(df, df_cleaned)\n",
    "\n",
    "# 3 Define feature categories (includes Analyst Targets & Ratings)\n",
    "categories = {\n",
    "    \"Analyst_Targets_Ratings\": [\n",
    "        \"target_from\",\n",
    "        \"rating_from_score\",\n",
    "        \"rating_delta\",\n",
    "        \"target_delta\",\n",
    "        \"target_growth\",\n",
    "        \"relative_growth\"\n",
    "    ],\n",
    "    \"Volatility_Range\": [\"atr\", \"std_dev\", \"ulcer_index\", \"price_distance\"],\n",
    "    \"Cumulative_Volume\": [\"obv\", \"ad_line\", \"pvt\", \"force_index\"],\n",
    "    \"Price_Filters\": [\"hlc3\", \"typical_price\", \"vwap\", \"last_close\"]\n",
    "}\n",
    "\n",
    "# 4 Normalize features (0–10 scale) per cluster\n",
    "# Check if cluster column exists\n",
    "if 'cluster' not in df.columns:\n",
    "    print(\"Warning: 'cluster' column not found. Normalizing across entire dataset.\")\n",
    "    scaler = MinMaxScaler(feature_range=(0, 10))\n",
    "    for cat, feats in categories.items():\n",
    "        for f in feats:\n",
    "            col = f\"norm_{f}\"\n",
    "            if f in df.columns:\n",
    "                df[col] = scaler.fit_transform(df[[f]])\n",
    "            else:\n",
    "                print(f\"Missing feature: {f}\")\n",
    "else:\n",
    "    # Normalize per cluster - fit scaler separately for each cluster\n",
    "    for cat, feats in categories.items():\n",
    "        for f in feats:\n",
    "            col = f\"norm_{f}\"\n",
    "            if f in df.columns:\n",
    "                # Normalize within each cluster\n",
    "                df[col] = df.groupby('cluster')[f].transform(\n",
    "                    lambda x: MinMaxScaler(feature_range=(0, 10)).fit_transform(x.values.reshape(-1, 1)).flatten()\n",
    "                )\n",
    "            else:\n",
    "                print(f\"Missing feature: {f}\")\n",
    "\n",
    "# 5 Compute category-level averages\n",
    "for cat, feats in categories.items():\n",
    "    norm_feats = [f\"norm_{f}\" for f in feats if f\"norm_{f}\" in df.columns]\n",
    "    if norm_feats:\n",
    "        df[f\"{cat.lower()}_score\"] = df[norm_feats].mean(axis=1)\n",
    "\n",
    "# 6 Compute overall final score (average of all category scores)\n",
    "category_scores = [f\"{cat.lower()}_score\" for cat in categories.keys() if f\"{cat.lower()}_score\" in df.columns]\n",
    "df[\"final_score\"] = df[category_scores].mean(axis=1)\n",
    "\n",
    "# 7 Save and preview results\n",
    "df.to_csv(\"stock_data_with_scores2.csv\", index=False)\n",
    "print(\"Final dataset saved to stock_data_with_scores.csv\")\n",
    "print(df[[\"ticker\", \"date\", \"final_score\"] + category_scores].head())\n",
    "print(df.describe())\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset saved to stock_data_with_scores.csv\n",
      "  ticker                 date  final_score  analyst_targets_ratings_score  \\\n",
      "0   CECO  2025-08-22 00:30:05     1.730154                       3.956294   \n",
      "1   BLND  2025-08-25 00:30:04     1.723056                       3.545262   \n",
      "2   FLOC  2025-08-07 00:30:07     1.698187                       3.641419   \n",
      "3   VYGR  2025-09-16 00:30:09     1.670876                       3.703916   \n",
      "4   BCBP  2025-07-31 00:30:08     1.793695                       3.975387   \n",
      "\n",
      "   volatility_range_score  cumulative_volume_score  price_filters_score  \n",
      "0                1.015578                 1.856554             0.092192  \n",
      "1                1.480559                 1.859899             0.006503  \n",
      "2                1.290756                 1.830299             0.030276  \n",
      "3                1.114417                 1.857361             0.007812  \n",
      "4                0.900701                 2.288788             0.009904  \n",
      "       target_from    target_to  rating_from_score  rating_to_score  \\\n",
      "count  2733.000000  2733.000000        2733.000000      2733.000000   \n",
      "mean     77.344757    78.894826           1.145993         1.130626   \n",
      "std     111.143404   112.969116           1.211334         1.232545   \n",
      "min       0.000000     0.000000          -3.000000        -3.000000   \n",
      "25%      14.600000    15.000000           0.000000         0.000000   \n",
      "50%      35.000000    36.000000           2.000000         2.000000   \n",
      "75%      90.000000    90.000000           2.000000         2.000000   \n",
      "max     920.000000   947.000000           3.000000         3.000000   \n",
      "\n",
      "       rating_delta  rating_magnitude  target_delta  target_growth  \\\n",
      "count   2733.000000       2733.000000   2733.000000    2733.000000   \n",
      "mean      -0.015368          0.211489      1.550070       0.041304   \n",
      "std        0.685916          0.652666     37.166758       0.232261   \n",
      "min       -5.000000          0.000000   -920.000000      -1.000000   \n",
      "25%        0.000000          0.000000     -0.500000      -0.012346   \n",
      "50%        0.000000          0.000000      0.000000       0.000000   \n",
      "75%        0.000000          0.000000      3.000000       0.083333   \n",
      "max        5.000000          5.000000    947.000000       4.000000   \n",
      "\n",
      "       relative_growth   last_close  ...  norm_force_index    norm_hlc3  \\\n",
      "count      2733.000000  2733.000000  ...       2733.000000  2733.000000   \n",
      "mean          0.001959    80.891943  ...          2.853877     0.328685   \n",
      "std          24.024447   231.994697  ...          1.424557     0.924643   \n",
      "min        -595.684401     0.270000  ...          0.000000     0.000000   \n",
      "25%          -1.323198    10.260000  ...          1.894482     0.019064   \n",
      "50%          -1.000000    29.810463  ...          2.765211     0.060352   \n",
      "75%           0.939188    81.930000  ...          2.780792     0.181428   \n",
      "max         611.137095  7430.919922  ...         10.000000    10.000000   \n",
      "\n",
      "       norm_typical_price    norm_vwap  norm_last_close  \\\n",
      "count         2733.000000  2733.000000      2733.000000   \n",
      "mean             0.328685     0.328685         0.330239   \n",
      "std              0.924643     0.924643         0.930205   \n",
      "min              0.000000     0.000000         0.000000   \n",
      "25%              0.019064     0.019064         0.019044   \n",
      "50%              0.060352     0.060352         0.060328   \n",
      "75%              0.181428     0.181428         0.182096   \n",
      "max             10.000000    10.000000        10.000000   \n",
      "\n",
      "       analyst_targets_ratings_score  volatility_range_score  \\\n",
      "count                    2733.000000             2733.000000   \n",
      "mean                        4.089884                1.406913   \n",
      "std                         0.883252                0.667961   \n",
      "min                         1.343801                0.611162   \n",
      "25%                         3.633403                0.986082   \n",
      "50%                         3.899869                1.188146   \n",
      "75%                         4.312836                1.601396   \n",
      "max                         8.641169                6.343919   \n",
      "\n",
      "       cumulative_volume_score  price_filters_score  final_score  \n",
      "count              2733.000000          2733.000000  2733.000000  \n",
      "mean                  2.264518             0.329073     2.022597  \n",
      "std                   0.698278             0.926026     0.603972  \n",
      "min                   0.787135             0.000000     1.329944  \n",
      "25%                   1.844523             0.019069     1.701967  \n",
      "50%                   2.013570             0.060386     1.833623  \n",
      "75%                   2.304383             0.181640     2.009486  \n",
      "max                   8.701293            10.000000     6.738447  \n",
      "\n",
      "[8 rows x 51 columns]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed2b672-1541-4293-a0dd-7251580208f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T01:53:36.376460Z",
     "start_time": "2025-11-01T01:53:36.374915Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47d032af",
   "metadata": {},
   "source": [
    "## Results and Conclusion\n",
    "\n",
    "### Process Description\n",
    "The scoring system successfully integrates multiple data sources and generates comprehensive buy signals by normalizing features across four categories and calculating weighted scores.\n",
    "\n",
    "### Key Activities\n",
    "- **Data Integration**: Successfully merged clustered data with technical indicators\n",
    "- **Feature Normalization**: Scaled all features to 0-10 range for fair comparison\n",
    "- **Category Scoring**: Generated scores for Analyst, Volatility, Volume, and Price categories\n",
    "- **Final Score Calculation**: Created overall buy signals ranging from 0-10\n",
    "\n",
    "### Conclusion\n",
    "The feature scoring system successfully created a comprehensive buy signal framework that combines analyst sentiment, technical indicators, and market dynamics. The final scores provide actionable investment signals with scores ranging from 1.8 to 2.1, indicating a conservative to moderate buy signal range. The category-based approach ensures balanced evaluation across different market factors, while the normalization process enables fair comparison between diverse feature types. This scoring system provides a robust foundation for investment decision support and portfolio management.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
